# PIPELINE DEFINITION
# Name: diabetes-classification-pipeline
# Description: A demonstration pipeline for diabetes classification using multiple models
# Inputs:
#    dt_max_depth: int [Default: 5.0]
#    random_state: int [Default: 42.0]
#    rf_n_estimators: int [Default: 100.0]
#    svm_c: float [Default: 1.0]
#    svm_kernel: str [Default: 'rbf']
#    test_size: float [Default: 0.3]
components:
  comp-compare-models:
    executorLabel: exec-compare-models
    inputDefinitions:
      artifacts:
        dt_metrics_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        rf_metrics_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        svm_metrics_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        comparison_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-evaluate-model:
    executorLabel: exec-evaluate-model
    inputDefinitions:
      artifacts:
        feature_names_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        model_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        x_test_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        y_test_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        model_name:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        metrics_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        plots_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-evaluate-model-2:
    executorLabel: exec-evaluate-model-2
    inputDefinitions:
      artifacts:
        feature_names_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        model_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        x_test_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        y_test_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        model_name:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        metrics_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        plots_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-evaluate-model-3:
    executorLabel: exec-evaluate-model-3
    inputDefinitions:
      artifacts:
        feature_names_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        model_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        x_test_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        y_test_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        model_name:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        metrics_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        plots_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-load-data:
    executorLabel: exec-load-data
    outputDefinitions:
      artifacts:
        feature_names_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        metadata_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        x_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        y_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-preprocess-data:
    executorLabel: exec-preprocess-data
    inputDefinitions:
      artifacts:
        x_test_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        x_train_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        scaler_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        x_test_scaled_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        x_train_scaled_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-split-data:
    executorLabel: exec-split-data
    inputDefinitions:
      artifacts:
        x_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        y_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        random_state:
          defaultValue: 42.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        test_size:
          defaultValue: 0.3
          isOptional: true
          parameterType: NUMBER_DOUBLE
    outputDefinitions:
      artifacts:
        split_info_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        x_test_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        x_train_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        y_test_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        y_train_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-train-decision-tree:
    executorLabel: exec-train-decision-tree
    inputDefinitions:
      artifacts:
        x_train_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        y_train_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        max_depth:
          defaultValue: 5.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        random_state:
          defaultValue: 42.0
          isOptional: true
          parameterType: NUMBER_INTEGER
    outputDefinitions:
      artifacts:
        model_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-train-random-forest:
    executorLabel: exec-train-random-forest
    inputDefinitions:
      artifacts:
        x_train_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        y_train_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        n_estimators:
          defaultValue: 100.0
          isOptional: true
          parameterType: NUMBER_INTEGER
        random_state:
          defaultValue: 42.0
          isOptional: true
          parameterType: NUMBER_INTEGER
    outputDefinitions:
      artifacts:
        model_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-train-svm:
    executorLabel: exec-train-svm
    inputDefinitions:
      artifacts:
        x_train_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
        y_train_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        C:
          defaultValue: 1.0
          isOptional: true
          parameterType: NUMBER_DOUBLE
        kernel:
          defaultValue: rbf
          isOptional: true
          parameterType: STRING
        random_state:
          defaultValue: 42.0
          isOptional: true
          parameterType: NUMBER_INTEGER
    outputDefinitions:
      artifacts:
        model_path:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
deploymentSpec:
  executors:
    exec-compare-models:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - compare_models
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'matplotlib'\
          \ && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef compare_models(dt_metrics_path: dsl.InputPath(), \n         \
          \         rf_metrics_path: dsl.InputPath(), \n                  svm_metrics_path:\
          \ dsl.InputPath(),\n                  comparison_path: dsl.OutputPath()):\n\
          \    import json\n    import matplotlib.pyplot as plt\n    import base64\n\
          \    from io import BytesIO\n\n    # Load metrics for each model\n    with\
          \ open(dt_metrics_path, 'r') as f:\n        dt_metrics = json.load(f)\n\n\
          \    with open(rf_metrics_path, 'r') as f:\n        rf_metrics = json.load(f)\n\
          \n    with open(svm_metrics_path, 'r') as f:\n        svm_metrics = json.load(f)\n\
          \n    # Combine metrics\n    models = [dt_metrics, rf_metrics, svm_metrics]\n\
          \    model_names = [model[\"model_name\"] for model in models]\n    accuracies\
          \ = [model[\"accuracy\"] for model in models]\n\n    # Find the best model\n\
          \    best_model_idx = accuracies.index(max(accuracies))\n    best_model\
          \ = model_names[best_model_idx]\n\n    # Create comparison plot\n    plt.figure(figsize=(10,\
          \ 6))\n    bars = plt.bar(model_names, accuracies, color=['blue', 'green',\
          \ 'red'])\n    plt.xlabel('Model')\n    plt.ylabel('Accuracy')\n    plt.title('Model\
          \ Comparison - Diabetes Classification')\n    plt.ylim([0, 1])\n\n    #\
          \ Highlight the best model\n    bars[best_model_idx].set_color('gold')\n\
          \n    # Add text annotations\n    for i, acc in enumerate(accuracies):\n\
          \        plt.text(i, acc + 0.02, f'{acc:.4f}', ha='center')\n\n    plt.tight_layout()\n\
          \n    # Save the comparison plot\n    buffer = BytesIO()\n    plt.savefig(buffer,\
          \ format='png')\n    buffer.seek(0)\n    comparison_image = base64.b64encode(buffer.read()).decode('utf-8')\n\
          \    plt.close()\n\n    # Prepare comparison results\n    comparison_results\
          \ = {\n        \"model_names\": model_names,\n        \"accuracies\": accuracies,\n\
          \        \"best_model\": best_model,\n        \"best_accuracy\": accuracies[best_model_idx],\n\
          \        \"comparison_plot\": comparison_image\n    }\n\n    # Save comparison\
          \ results\n    with open(comparison_path, 'w') as f:\n        json.dump(comparison_results,\
          \ f)\n\n"
        image: python:3.9
    exec-evaluate-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - evaluate_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'numpy' 'scikit-learn'\
          \ 'joblib' 'matplotlib' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef evaluate_model(model_path: dsl.InputPath(), \n              \
          \    x_test_path: dsl.InputPath(), \n                  y_test_path: dsl.InputPath(),\
          \ \n                  feature_names_path: dsl.InputPath(), \n          \
          \        model_name: str,\n                  metrics_path: dsl.OutputPath(),\n\
          \                  plots_path: dsl.OutputPath()):\n    import joblib\n \
          \   import numpy as np\n    from sklearn.metrics import accuracy_score,\
          \ classification_report, confusion_matrix, roc_curve, auc\n    import matplotlib.pyplot\
          \ as plt\n    import json\n    import base64\n    from io import BytesIO\n\
          \n    # Load model, test data, and feature names\n    model = joblib.load(model_path)\n\
          \    X_test = joblib.load(x_test_path)\n    y_test = joblib.load(y_test_path)\n\
          \    feature_names = joblib.load(feature_names_path)\n\n    # Make predictions\n\
          \    y_pred = model.predict(X_test)\n    y_pred_proba = model.predict_proba(X_test)[:,\
          \ 1] if hasattr(model, \"predict_proba\") else None\n\n    # Calculate metrics\n\
          \    accuracy = accuracy_score(y_test, y_pred)\n    class_report = classification_report(y_test,\
          \ y_pred, output_dict=True)\n    conf_matrix = confusion_matrix(y_test,\
          \ y_pred).tolist()\n\n    # Store metrics\n    metrics = {\n        \"model_name\"\
          : model_name,\n        \"accuracy\": float(accuracy),\n        \"classification_report\"\
          : class_report,\n        \"confusion_matrix\": conf_matrix\n    }\n\n  \
          \  # Generate plots and convert to base64 strings\n    plots = {}\n\n  \
          \  # Create confusion matrix visualization\n    plt.figure(figsize=(8, 6))\n\
          \    plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n\
          \    plt.title(f'Confusion Matrix - {model_name}')\n    plt.colorbar()\n\
          \    classes = ['Negative', 'Positive']\n    tick_marks = np.arange(len(classes))\n\
          \    plt.xticks(tick_marks, classes)\n    plt.yticks(tick_marks, classes)\n\
          \n    # Add text annotations to confusion matrix cells\n    thresh = np.array(conf_matrix).max()\
          \ / 2\n    for i in range(len(classes)):\n        for j in range(len(classes)):\n\
          \            plt.text(j, i, conf_matrix[i][j],\n                     horizontalalignment=\"\
          center\",\n                     color=\"white\" if conf_matrix[i][j] > thresh\
          \ else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n\
          \    plt.xlabel('Predicted label')\n\n    # Save the confusion matrix plot\n\
          \    buffer = BytesIO()\n    plt.savefig(buffer, format='png')\n    buffer.seek(0)\n\
          \    conf_matrix_image = base64.b64encode(buffer.read()).decode('utf-8')\n\
          \    plots[\"confusion_matrix\"] = conf_matrix_image\n    plt.close()\n\n\
          \    # Create ROC curve if probability predictions are available\n    if\
          \ y_pred_proba is not None:\n        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n\
          \        roc_auc = auc(fpr, tpr)\n\n        plt.figure(figsize=(8, 6))\n\
          \        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve\
          \ (area = {roc_auc:.2f})')\n        plt.plot([0, 1], [0, 1], color='navy',\
          \ lw=2, linestyle='--')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0,\
          \ 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True\
          \ Positive Rate')\n        plt.title(f'ROC Curve - {model_name}')\n    \
          \    plt.legend(loc=\"lower right\")\n\n        buffer = BytesIO()\n   \
          \     plt.savefig(buffer, format='png')\n        buffer.seek(0)\n      \
          \  roc_image = base64.b64encode(buffer.read()).decode('utf-8')\n       \
          \ plots[\"roc_curve\"] = roc_image\n\n        # Add AUC to metrics\n   \
          \     metrics[\"roc_auc\"] = float(roc_auc)\n        plt.close()\n\n   \
          \ # For tree-based models, create feature importance plot\n    if hasattr(model,\
          \ 'feature_importances_'):\n        importances = model.feature_importances_\n\
          \n        plt.figure(figsize=(10, 6))\n        indices = np.argsort(importances)[::-1]\n\
          \        plt.bar(range(len(importances)), importances[indices])\n      \
          \  plt.title(f'Feature Importance - {model_name}')\n        plt.xticks(range(len(importances)),\
          \ [feature_names[i] for i in indices], rotation=90)\n        plt.tight_layout()\n\
          \n        buffer = BytesIO()\n        plt.savefig(buffer, format='png')\n\
          \        buffer.seek(0)\n        importance_image = base64.b64encode(buffer.read()).decode('utf-8')\n\
          \        plots[\"feature_importance\"] = importance_image\n\n        # Add\
          \ feature importances to metrics\n        metrics[\"feature_importances\"\
          ] = dict(zip([feature_names[i] for i in indices], importances[indices].tolist()))\n\
          \        plt.close()\n\n    # Save the metrics and plots\n    with open(metrics_path,\
          \ 'w') as f:\n        json.dump(metrics, f)\n\n    with open(plots_path,\
          \ 'w') as f:\n        json.dump(plots, f)\n\n"
        image: python:3.9
    exec-evaluate-model-2:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - evaluate_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'numpy' 'scikit-learn'\
          \ 'joblib' 'matplotlib' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef evaluate_model(model_path: dsl.InputPath(), \n              \
          \    x_test_path: dsl.InputPath(), \n                  y_test_path: dsl.InputPath(),\
          \ \n                  feature_names_path: dsl.InputPath(), \n          \
          \        model_name: str,\n                  metrics_path: dsl.OutputPath(),\n\
          \                  plots_path: dsl.OutputPath()):\n    import joblib\n \
          \   import numpy as np\n    from sklearn.metrics import accuracy_score,\
          \ classification_report, confusion_matrix, roc_curve, auc\n    import matplotlib.pyplot\
          \ as plt\n    import json\n    import base64\n    from io import BytesIO\n\
          \n    # Load model, test data, and feature names\n    model = joblib.load(model_path)\n\
          \    X_test = joblib.load(x_test_path)\n    y_test = joblib.load(y_test_path)\n\
          \    feature_names = joblib.load(feature_names_path)\n\n    # Make predictions\n\
          \    y_pred = model.predict(X_test)\n    y_pred_proba = model.predict_proba(X_test)[:,\
          \ 1] if hasattr(model, \"predict_proba\") else None\n\n    # Calculate metrics\n\
          \    accuracy = accuracy_score(y_test, y_pred)\n    class_report = classification_report(y_test,\
          \ y_pred, output_dict=True)\n    conf_matrix = confusion_matrix(y_test,\
          \ y_pred).tolist()\n\n    # Store metrics\n    metrics = {\n        \"model_name\"\
          : model_name,\n        \"accuracy\": float(accuracy),\n        \"classification_report\"\
          : class_report,\n        \"confusion_matrix\": conf_matrix\n    }\n\n  \
          \  # Generate plots and convert to base64 strings\n    plots = {}\n\n  \
          \  # Create confusion matrix visualization\n    plt.figure(figsize=(8, 6))\n\
          \    plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n\
          \    plt.title(f'Confusion Matrix - {model_name}')\n    plt.colorbar()\n\
          \    classes = ['Negative', 'Positive']\n    tick_marks = np.arange(len(classes))\n\
          \    plt.xticks(tick_marks, classes)\n    plt.yticks(tick_marks, classes)\n\
          \n    # Add text annotations to confusion matrix cells\n    thresh = np.array(conf_matrix).max()\
          \ / 2\n    for i in range(len(classes)):\n        for j in range(len(classes)):\n\
          \            plt.text(j, i, conf_matrix[i][j],\n                     horizontalalignment=\"\
          center\",\n                     color=\"white\" if conf_matrix[i][j] > thresh\
          \ else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n\
          \    plt.xlabel('Predicted label')\n\n    # Save the confusion matrix plot\n\
          \    buffer = BytesIO()\n    plt.savefig(buffer, format='png')\n    buffer.seek(0)\n\
          \    conf_matrix_image = base64.b64encode(buffer.read()).decode('utf-8')\n\
          \    plots[\"confusion_matrix\"] = conf_matrix_image\n    plt.close()\n\n\
          \    # Create ROC curve if probability predictions are available\n    if\
          \ y_pred_proba is not None:\n        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n\
          \        roc_auc = auc(fpr, tpr)\n\n        plt.figure(figsize=(8, 6))\n\
          \        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve\
          \ (area = {roc_auc:.2f})')\n        plt.plot([0, 1], [0, 1], color='navy',\
          \ lw=2, linestyle='--')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0,\
          \ 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True\
          \ Positive Rate')\n        plt.title(f'ROC Curve - {model_name}')\n    \
          \    plt.legend(loc=\"lower right\")\n\n        buffer = BytesIO()\n   \
          \     plt.savefig(buffer, format='png')\n        buffer.seek(0)\n      \
          \  roc_image = base64.b64encode(buffer.read()).decode('utf-8')\n       \
          \ plots[\"roc_curve\"] = roc_image\n\n        # Add AUC to metrics\n   \
          \     metrics[\"roc_auc\"] = float(roc_auc)\n        plt.close()\n\n   \
          \ # For tree-based models, create feature importance plot\n    if hasattr(model,\
          \ 'feature_importances_'):\n        importances = model.feature_importances_\n\
          \n        plt.figure(figsize=(10, 6))\n        indices = np.argsort(importances)[::-1]\n\
          \        plt.bar(range(len(importances)), importances[indices])\n      \
          \  plt.title(f'Feature Importance - {model_name}')\n        plt.xticks(range(len(importances)),\
          \ [feature_names[i] for i in indices], rotation=90)\n        plt.tight_layout()\n\
          \n        buffer = BytesIO()\n        plt.savefig(buffer, format='png')\n\
          \        buffer.seek(0)\n        importance_image = base64.b64encode(buffer.read()).decode('utf-8')\n\
          \        plots[\"feature_importance\"] = importance_image\n\n        # Add\
          \ feature importances to metrics\n        metrics[\"feature_importances\"\
          ] = dict(zip([feature_names[i] for i in indices], importances[indices].tolist()))\n\
          \        plt.close()\n\n    # Save the metrics and plots\n    with open(metrics_path,\
          \ 'w') as f:\n        json.dump(metrics, f)\n\n    with open(plots_path,\
          \ 'w') as f:\n        json.dump(plots, f)\n\n"
        image: python:3.9
    exec-evaluate-model-3:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - evaluate_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'numpy' 'scikit-learn'\
          \ 'joblib' 'matplotlib' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef evaluate_model(model_path: dsl.InputPath(), \n              \
          \    x_test_path: dsl.InputPath(), \n                  y_test_path: dsl.InputPath(),\
          \ \n                  feature_names_path: dsl.InputPath(), \n          \
          \        model_name: str,\n                  metrics_path: dsl.OutputPath(),\n\
          \                  plots_path: dsl.OutputPath()):\n    import joblib\n \
          \   import numpy as np\n    from sklearn.metrics import accuracy_score,\
          \ classification_report, confusion_matrix, roc_curve, auc\n    import matplotlib.pyplot\
          \ as plt\n    import json\n    import base64\n    from io import BytesIO\n\
          \n    # Load model, test data, and feature names\n    model = joblib.load(model_path)\n\
          \    X_test = joblib.load(x_test_path)\n    y_test = joblib.load(y_test_path)\n\
          \    feature_names = joblib.load(feature_names_path)\n\n    # Make predictions\n\
          \    y_pred = model.predict(X_test)\n    y_pred_proba = model.predict_proba(X_test)[:,\
          \ 1] if hasattr(model, \"predict_proba\") else None\n\n    # Calculate metrics\n\
          \    accuracy = accuracy_score(y_test, y_pred)\n    class_report = classification_report(y_test,\
          \ y_pred, output_dict=True)\n    conf_matrix = confusion_matrix(y_test,\
          \ y_pred).tolist()\n\n    # Store metrics\n    metrics = {\n        \"model_name\"\
          : model_name,\n        \"accuracy\": float(accuracy),\n        \"classification_report\"\
          : class_report,\n        \"confusion_matrix\": conf_matrix\n    }\n\n  \
          \  # Generate plots and convert to base64 strings\n    plots = {}\n\n  \
          \  # Create confusion matrix visualization\n    plt.figure(figsize=(8, 6))\n\
          \    plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n\
          \    plt.title(f'Confusion Matrix - {model_name}')\n    plt.colorbar()\n\
          \    classes = ['Negative', 'Positive']\n    tick_marks = np.arange(len(classes))\n\
          \    plt.xticks(tick_marks, classes)\n    plt.yticks(tick_marks, classes)\n\
          \n    # Add text annotations to confusion matrix cells\n    thresh = np.array(conf_matrix).max()\
          \ / 2\n    for i in range(len(classes)):\n        for j in range(len(classes)):\n\
          \            plt.text(j, i, conf_matrix[i][j],\n                     horizontalalignment=\"\
          center\",\n                     color=\"white\" if conf_matrix[i][j] > thresh\
          \ else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n\
          \    plt.xlabel('Predicted label')\n\n    # Save the confusion matrix plot\n\
          \    buffer = BytesIO()\n    plt.savefig(buffer, format='png')\n    buffer.seek(0)\n\
          \    conf_matrix_image = base64.b64encode(buffer.read()).decode('utf-8')\n\
          \    plots[\"confusion_matrix\"] = conf_matrix_image\n    plt.close()\n\n\
          \    # Create ROC curve if probability predictions are available\n    if\
          \ y_pred_proba is not None:\n        fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n\
          \        roc_auc = auc(fpr, tpr)\n\n        plt.figure(figsize=(8, 6))\n\
          \        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve\
          \ (area = {roc_auc:.2f})')\n        plt.plot([0, 1], [0, 1], color='navy',\
          \ lw=2, linestyle='--')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0,\
          \ 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True\
          \ Positive Rate')\n        plt.title(f'ROC Curve - {model_name}')\n    \
          \    plt.legend(loc=\"lower right\")\n\n        buffer = BytesIO()\n   \
          \     plt.savefig(buffer, format='png')\n        buffer.seek(0)\n      \
          \  roc_image = base64.b64encode(buffer.read()).decode('utf-8')\n       \
          \ plots[\"roc_curve\"] = roc_image\n\n        # Add AUC to metrics\n   \
          \     metrics[\"roc_auc\"] = float(roc_auc)\n        plt.close()\n\n   \
          \ # For tree-based models, create feature importance plot\n    if hasattr(model,\
          \ 'feature_importances_'):\n        importances = model.feature_importances_\n\
          \n        plt.figure(figsize=(10, 6))\n        indices = np.argsort(importances)[::-1]\n\
          \        plt.bar(range(len(importances)), importances[indices])\n      \
          \  plt.title(f'Feature Importance - {model_name}')\n        plt.xticks(range(len(importances)),\
          \ [feature_names[i] for i in indices], rotation=90)\n        plt.tight_layout()\n\
          \n        buffer = BytesIO()\n        plt.savefig(buffer, format='png')\n\
          \        buffer.seek(0)\n        importance_image = base64.b64encode(buffer.read()).decode('utf-8')\n\
          \        plots[\"feature_importance\"] = importance_image\n\n        # Add\
          \ feature importances to metrics\n        metrics[\"feature_importances\"\
          ] = dict(zip([feature_names[i] for i in indices], importances[indices].tolist()))\n\
          \        plt.close()\n\n    # Save the metrics and plots\n    with open(metrics_path,\
          \ 'w') as f:\n        json.dump(metrics, f)\n\n    with open(plots_path,\
          \ 'w') as f:\n        json.dump(plots, f)\n\n"
        image: python:3.9
    exec-load-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - load_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'numpy' 'scikit-learn'\
          \ 'joblib' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef load_data(x_path: dsl.OutputPath(), \n              y_path: dsl.OutputPath(),\
          \ \n              feature_names_path: dsl.OutputPath(), \n             \
          \ metadata_path: dsl.OutputPath()):\n    import numpy as np\n    from sklearn.datasets\
          \ import load_diabetes\n    import joblib\n    import json\n\n    # Load\
          \ diabetes dataset\n    diabetes = load_diabetes()\n    X = diabetes.data\n\
          \n    # Convert to binary classification (above/below median)\n    y = (diabetes.target\
          \ > np.median(diabetes.target)).astype(int)\n\n    # Save feature names\
          \ for later use\n    feature_names = diabetes.feature_names\n\n    # Save\
          \ data to files - use direct paths for OutputPath\n    joblib.dump(X, x_path)\n\
          \    joblib.dump(y, y_path)\n    joblib.dump(feature_names, feature_names_path)\n\
          \n    # Generate dataset metadata\n    metadata = {\n        \"num_samples\"\
          : X.shape[0],\n        \"num_features\": X.shape[1],\n        \"class_distribution\"\
          : np.bincount(y).tolist(),\n        \"feature_names\": list(feature_names)\n\
          \    }\n\n    with open(metadata_path, 'w') as f:\n        json.dump(metadata,\
          \ f)\n\n"
        image: python:3.9
    exec-preprocess-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - preprocess_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'scikit-learn'\
          \ 'joblib' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef preprocess_data(x_train_path: dsl.InputPath(), \n           \
          \         x_test_path: dsl.InputPath(),\n                    x_train_scaled_path:\
          \ dsl.OutputPath(),\n                    x_test_scaled_path: dsl.OutputPath(),\n\
          \                    scaler_path: dsl.OutputPath()):\n    import joblib\n\
          \    from sklearn.preprocessing import StandardScaler\n\n    # Load training\
          \ and test data\n    X_train = joblib.load(x_train_path)\n    X_test = joblib.load(x_test_path)\n\
          \n    # Initialize and fit the scaler\n    scaler = StandardScaler()\n \
          \   X_train_scaled = scaler.fit_transform(X_train)\n    X_test_scaled =\
          \ scaler.transform(X_test)\n\n    # Save the preprocessed data and the scaler\n\
          \    joblib.dump(X_train_scaled, x_train_scaled_path)\n    joblib.dump(X_test_scaled,\
          \ x_test_scaled_path)\n    joblib.dump(scaler, scaler_path)\n\n"
        image: python:3.9
    exec-split-data:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - split_data
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'numpy' 'scikit-learn'\
          \ 'joblib' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef split_data(x_path: dsl.InputPath(), \n               y_path:\
          \ dsl.InputPath(), \n               x_train_path: dsl.OutputPath(),\n  \
          \             x_test_path: dsl.OutputPath(),\n               y_train_path:\
          \ dsl.OutputPath(),\n               y_test_path: dsl.OutputPath(),\n   \
          \            split_info_path: dsl.OutputPath(),\n               test_size:\
          \ float = 0.3, \n               random_state: int = 42):\n    import joblib\n\
          \    import numpy as np\n    import json\n    from sklearn.model_selection\
          \ import train_test_split\n\n    # Load the data\n    X = joblib.load(x_path)\n\
          \    y = joblib.load(y_path)\n\n    # Split the data\n    X_train, X_test,\
          \ y_train, y_test = train_test_split(\n        X, y, test_size=test_size,\
          \ random_state=random_state, stratify=y\n    )\n\n    # Save the splits\n\
          \    joblib.dump(X_train, x_train_path)\n    joblib.dump(X_test, x_test_path)\n\
          \    joblib.dump(y_train, y_train_path)\n    joblib.dump(y_test, y_test_path)\n\
          \n    # Convert numpy types to native Python types for JSON serialization\n\
          \    train_unique, train_counts = np.unique(y_train, return_counts=True)\n\
          \    test_unique, test_counts = np.unique(y_test, return_counts=True)\n\n\
          \    # Convert numpy arrays to regular Python lists/types\n    train_class_distribution\
          \ = {int(k): int(v) for k, v in zip(train_unique, train_counts)}\n    test_class_distribution\
          \ = {int(k): int(v) for k, v in zip(test_unique, test_counts)}\n\n    split_info\
          \ = {\n        \"train_samples\": int(X_train.shape[0]),\n        \"test_samples\"\
          : int(X_test.shape[0]),\n        \"train_class_distribution\": train_class_distribution,\n\
          \        \"test_class_distribution\": test_class_distribution\n    }\n\n\
          \    with open(split_info_path, 'w') as f:\n        json.dump(split_info,\
          \ f)\n\n"
        image: python:3.9
    exec-train-decision-tree:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train_decision_tree
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'scikit-learn'\
          \ 'joblib' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef train_decision_tree(x_train_path: dsl.InputPath(), \n       \
          \                 y_train_path: dsl.InputPath(), \n                    \
          \    model_path: dsl.OutputPath(),\n                        max_depth: int\
          \ = 5, \n                        random_state: int = 42):\n    import joblib\n\
          \    from sklearn.tree import DecisionTreeClassifier\n\n    # Load training\
          \ data\n    X_train = joblib.load(x_train_path)\n    y_train = joblib.load(y_train_path)\n\
          \n    # Train the model\n    model = DecisionTreeClassifier(max_depth=max_depth,\
          \ random_state=random_state)\n    model.fit(X_train, y_train)\n\n    # Save\
          \ the model\n    joblib.dump(model, model_path)\n\n"
        image: python:3.9
    exec-train-random-forest:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train_random_forest
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'scikit-learn'\
          \ 'joblib' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef train_random_forest(x_train_path: dsl.InputPath(), \n       \
          \                y_train_path: dsl.InputPath(), \n                     \
          \  model_path: dsl.OutputPath(),\n                       n_estimators: int\
          \ = 100, \n                       random_state: int = 42):\n    import joblib\n\
          \    from sklearn.ensemble import RandomForestClassifier\n\n    # Load training\
          \ data\n    X_train = joblib.load(x_train_path)\n    y_train = joblib.load(y_train_path)\n\
          \n    # Train the model\n    model = RandomForestClassifier(n_estimators=n_estimators,\
          \ random_state=random_state)\n    model.fit(X_train, y_train)\n\n    # Save\
          \ the model\n    joblib.dump(model, model_path)\n\n"
        image: python:3.9
    exec-train-svm:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train_svm
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.11.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'scikit-learn'\
          \ 'joblib' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef train_svm(x_train_path: dsl.InputPath(), \n             y_train_path:\
          \ dsl.InputPath(), \n             model_path: dsl.OutputPath(),\n      \
          \       C: float = 1.0, \n             kernel: str = 'rbf', \n         \
          \    random_state: int = 42):\n    import joblib\n    from sklearn.svm import\
          \ SVC\n\n    # Load training data\n    X_train = joblib.load(x_train_path)\n\
          \    y_train = joblib.load(y_train_path)\n\n    # Train the model\n    model\
          \ = SVC(C=C, kernel=kernel, random_state=random_state, probability=True)\n\
          \    model.fit(X_train, y_train)\n\n    # Save the model\n    joblib.dump(model,\
          \ model_path)\n\n"
        image: python:3.9
pipelineInfo:
  description: A demonstration pipeline for diabetes classification using multiple
    models
  name: diabetes-classification-pipeline
root:
  dag:
    tasks:
      compare-models:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-compare-models
        dependentTasks:
        - evaluate-model
        - evaluate-model-2
        - evaluate-model-3
        inputs:
          artifacts:
            dt_metrics_path:
              taskOutputArtifact:
                outputArtifactKey: metrics_path
                producerTask: evaluate-model
            rf_metrics_path:
              taskOutputArtifact:
                outputArtifactKey: metrics_path
                producerTask: evaluate-model-2
            svm_metrics_path:
              taskOutputArtifact:
                outputArtifactKey: metrics_path
                producerTask: evaluate-model-3
        taskInfo:
          name: compare-models
      evaluate-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-evaluate-model
        dependentTasks:
        - load-data
        - preprocess-data
        - split-data
        - train-decision-tree
        inputs:
          artifacts:
            feature_names_path:
              taskOutputArtifact:
                outputArtifactKey: feature_names_path
                producerTask: load-data
            model_path:
              taskOutputArtifact:
                outputArtifactKey: model_path
                producerTask: train-decision-tree
            x_test_path:
              taskOutputArtifact:
                outputArtifactKey: x_test_scaled_path
                producerTask: preprocess-data
            y_test_path:
              taskOutputArtifact:
                outputArtifactKey: y_test_path
                producerTask: split-data
          parameters:
            model_name:
              runtimeValue:
                constant: Decision Tree
        taskInfo:
          name: evaluate-model
      evaluate-model-2:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-evaluate-model-2
        dependentTasks:
        - load-data
        - preprocess-data
        - split-data
        - train-random-forest
        inputs:
          artifacts:
            feature_names_path:
              taskOutputArtifact:
                outputArtifactKey: feature_names_path
                producerTask: load-data
            model_path:
              taskOutputArtifact:
                outputArtifactKey: model_path
                producerTask: train-random-forest
            x_test_path:
              taskOutputArtifact:
                outputArtifactKey: x_test_scaled_path
                producerTask: preprocess-data
            y_test_path:
              taskOutputArtifact:
                outputArtifactKey: y_test_path
                producerTask: split-data
          parameters:
            model_name:
              runtimeValue:
                constant: Random Forest
        taskInfo:
          name: evaluate-model-2
      evaluate-model-3:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-evaluate-model-3
        dependentTasks:
        - load-data
        - preprocess-data
        - split-data
        - train-svm
        inputs:
          artifacts:
            feature_names_path:
              taskOutputArtifact:
                outputArtifactKey: feature_names_path
                producerTask: load-data
            model_path:
              taskOutputArtifact:
                outputArtifactKey: model_path
                producerTask: train-svm
            x_test_path:
              taskOutputArtifact:
                outputArtifactKey: x_test_scaled_path
                producerTask: preprocess-data
            y_test_path:
              taskOutputArtifact:
                outputArtifactKey: y_test_path
                producerTask: split-data
          parameters:
            model_name:
              runtimeValue:
                constant: Support Vector Machine
        taskInfo:
          name: evaluate-model-3
      load-data:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-load-data
        taskInfo:
          name: load-data
      preprocess-data:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-preprocess-data
        dependentTasks:
        - split-data
        inputs:
          artifacts:
            x_test_path:
              taskOutputArtifact:
                outputArtifactKey: x_test_path
                producerTask: split-data
            x_train_path:
              taskOutputArtifact:
                outputArtifactKey: x_train_path
                producerTask: split-data
        taskInfo:
          name: preprocess-data
      split-data:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-split-data
        dependentTasks:
        - load-data
        inputs:
          artifacts:
            x_path:
              taskOutputArtifact:
                outputArtifactKey: x_path
                producerTask: load-data
            y_path:
              taskOutputArtifact:
                outputArtifactKey: y_path
                producerTask: load-data
          parameters:
            random_state:
              componentInputParameter: random_state
            test_size:
              componentInputParameter: test_size
        taskInfo:
          name: split-data
      train-decision-tree:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train-decision-tree
        dependentTasks:
        - preprocess-data
        - split-data
        inputs:
          artifacts:
            x_train_path:
              taskOutputArtifact:
                outputArtifactKey: x_train_scaled_path
                producerTask: preprocess-data
            y_train_path:
              taskOutputArtifact:
                outputArtifactKey: y_train_path
                producerTask: split-data
          parameters:
            max_depth:
              componentInputParameter: dt_max_depth
            random_state:
              componentInputParameter: random_state
        taskInfo:
          name: train-decision-tree
      train-random-forest:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train-random-forest
        dependentTasks:
        - preprocess-data
        - split-data
        inputs:
          artifacts:
            x_train_path:
              taskOutputArtifact:
                outputArtifactKey: x_train_scaled_path
                producerTask: preprocess-data
            y_train_path:
              taskOutputArtifact:
                outputArtifactKey: y_train_path
                producerTask: split-data
          parameters:
            n_estimators:
              componentInputParameter: rf_n_estimators
            random_state:
              componentInputParameter: random_state
        taskInfo:
          name: train-random-forest
      train-svm:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train-svm
        dependentTasks:
        - preprocess-data
        - split-data
        inputs:
          artifacts:
            x_train_path:
              taskOutputArtifact:
                outputArtifactKey: x_train_scaled_path
                producerTask: preprocess-data
            y_train_path:
              taskOutputArtifact:
                outputArtifactKey: y_train_path
                producerTask: split-data
          parameters:
            C:
              componentInputParameter: svm_c
            kernel:
              componentInputParameter: svm_kernel
            random_state:
              componentInputParameter: random_state
        taskInfo:
          name: train-svm
  inputDefinitions:
    parameters:
      dt_max_depth:
        defaultValue: 5.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      random_state:
        defaultValue: 42.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      rf_n_estimators:
        defaultValue: 100.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      svm_c:
        defaultValue: 1.0
        isOptional: true
        parameterType: NUMBER_DOUBLE
      svm_kernel:
        defaultValue: rbf
        isOptional: true
        parameterType: STRING
      test_size:
        defaultValue: 0.3
        isOptional: true
        parameterType: NUMBER_DOUBLE
schemaVersion: 2.1.0
sdkVersion: kfp-2.11.0
